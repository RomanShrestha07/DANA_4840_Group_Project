
## Loading data

#### K-means: wdbc.data datasets
#### Hierarchical: mtcars.csv dataset

```{r}
data <- read.table("Dataset_Pat/wdbc.data", header = TRUE, sep = ",")
data <- data[, -c(1, 2)]
# drops <- "M"
# df <- df[, !(names(df) %in% drops)]
data <- scale(data)
View(data)

```

```{r}
## install.packages("factoextra")
library(factoextra)
library(hopkins)
library(ggplot2)
library(cluster)
library(clValid)
```

## 1. Assessing Clustering Tendency

#### 1.1. Statistical methods

```{r}
set.seed(25)
hopkins <- hopkins(data, m = ceiling(nrow(data) / 10))
hopkins
```


#### 1.2. Visual methods
```{r}
fviz_dist(dist(cars), show_labels = FALSE)+
labs(title = "Breast Cancer data")
```
## 2. PCA
```{r}
# Perform PCA
pca_result <- prcomp(data, center = TRUE, scale. = TRUE)

# Perform k-means clustering
set.seed(123)
kmeans_result <- kmeans(data, centers = 3) # Adjust the number of centers (clusters) as needed

# Extract the first two principal components
pc1 <- pca_result$x[, 1]
pc2 <- pca_result$x[, 2]

# Create a data frame for plotting
pca_data <- data.frame(PC1 = pc1, PC2 = pc2, Cluster = as.factor(kmeans_result$cluster))

# Plot the PCA results
ggplot(pca_data, aes(x = PC1, y = PC2, color = Cluster)) +
  geom_point(alpha = 0.5) +
  labs(title = "PCA of WDBC Dataset with K-means Clustering", x = "Principal Component 1", y = "Principal Component 2") +
  theme_minimal() +
  scale_color_manual(values = c("black", "blue", "skyblue")) # Adjust the colors as needed
```




## Elbow method

```{r}
fviz_nbclust(data, pam, method = "wss") + geom_vline(xintercept = 2, linetype = 2)
```



```{r}
# Estimating the optimal number of clusters
fviz_nbclust(data, kmeans, method = "wss") + geom_vline(xintercept = 2, linetype = 2)
# if n = k we will get 0
```
## Silhouette method
```{r}
# Silhouette method
fviz_nbclust(data, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
```
## GAP
```{r}
fviz_nbclust(data, kmeans, nstart = 25, method = "gap_stat", nboot = 50)+
labs(subtitle = "Gap statistic method")
```


```{r}
set.seed(123)
gap_stat <- clusGap(data, FUN = kmeans, nstart = 25, K.max = 10, B = 50)

# Create a data frame for plotting
gap_df <- as.data.frame(gap_stat$Tab)
gap_df$k <- 1:nrow(gap_df)

# Calculate the y-values for the bar plot
gap_df$gap_diff <- gap_df$gap - c(gap_df$gap[-1], NA)

# Plot the gap statistic
ggplot(gap_df, aes(x = k, y = gap_diff)) +
  geom_bar(stat = "identity", fill = "steelblue", color = "black", width = 0.7) +
  scale_x_continuous(breaks = 1:10, limits = c(1, 10)) +
  scale_y_continuous(limits = c(-0.15, 0.25), expand = c(0, 0)) +
  labs(
    title = "Gap Statistic for Optimal Number of Clusters",
    x = "Number of clusters K",
    y = expression(Gap(k) - (Gap(k+1) - s[k+1]))
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.title.x = element_text(size = 14, face = "bold"),
    axis.title.y = element_text(size = 14, face = "bold"),
    axis.text = element_text(size = 12),
    panel.grid.major = element_line(color = "gray85"),
    panel.grid.minor = element_line(color = "gray90"),
    panel.grid.major.x = element_blank()
  )
```


```{r}
set.seed(123)
km.res <- kmeans(data, 2, nstart = 25)
```



```{r}
fviz_cluster(km.res, data = data,
             palette = c( "lightblue", "blue"),
             ellipse.type = "euclid", #Concentration ellipse
             star.plot = TRUE, #Add segments from centroids to items
             ggtheme = theme_minimal()
             )
```

## 3. Internal Validation
```{r}
# Perform internal validation
intern <- clValid(data, 2:6, clMethods = c("hierarchical", "kmeans", "pam"), validation = "internal")

# Display the summary of the internal validation results
summary(intern)
```

```{r}
# Set graphical parameters to combine plots
op <- par(no.readonly = TRUE)
par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))

# Plot the validation results without legends
plot(intern, legend = FALSE)

# Custom plot for the legend
plot(nClusters(intern), measures(intern, "Dunn")[,,1], type = "n", axes = FALSE, xlab = "", ylab = "")
legend("center", clusterMethods(intern), col = 1:9, lty = 1:9, pch = paste(1:9))

# Reset graphical parameters
par(op)
```

```{r}
# Display the optimal scores and corresponding clustering methods
optimal_scores <- summary(intern)$OptimalScores
print(optimal_scores)

```

## 3.2. Stability Validation

```{r}
# Perform stability validation
stab <- clValid(data, 2:6, clMethods = c("hierarchical", "kmeans", "pam"), validation = "stability")

# Display the optimal scores using the optimalScores method
optimal_scores_stab <- optimalScores(stab)
print(optimal_scores_stab)

```


```{r}
# Set graphical parameters to combine plots
op <- par(no.readonly = TRUE)
par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))

# Plot the stability validation results without legends
plot(stab, measure = c("APN", "AD", "ADM", "FOM"), legend = FALSE)

# Custom plot for the legend
plot(nClusters(stab), measures(stab, "APN")[,,1], type = "n", axes = FALSE, xlab = "", ylab = "")
legend("center", clusterMethods(stab), col = 1:9, lty = 1:9, pch = paste(1:9))

# Reset graphical parameters
par(op)
```


