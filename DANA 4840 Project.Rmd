---
title: "DANA 4840 Group Project"
author: ""
output: html_document
---

## Loading the libraries
```{r loading_libraries, message = FALSE}
library("ggplot2")
library("factoextra")
library("dendextend")
library("hopkins")
library("corrplot")
library("cluster")
library("patchwork")
library("clValid")
```

## 1. Loading the Datasets
### 1.1. K-means Clustering: wdbc
```{r read_wdbc}
wdbc <- read.csv("data/wdbc_kaggle.csv", header = T, sep = ",")
head(wdbc)
```

#### 1.1.2. Checking the internal structure: wdbc
```{r}
dim(wdbc)
str(wdbc)
```

#### 1.1.3. Pre-processing and Normalizing: wdbc
```{r}
diagnosis <- wdbc$diagnosis
wdbc_numerical <- wdbc[, -c(1, 2)]

wdbc_scaled <- data.frame(scale(wdbc_numerical))
rownames(wdbc_scaled) <- wdbc$ID
wdbc <- wdbc_scaled
head(wdbc)
```

#### 1.1.4. EDA: wdbc
```{r}
missing_wdbc <- sapply(wdbc, function(x) sum(is.na(x)))
missing_wdbc
```

```{r}
mean_columns <- grep("_mean", names(wdbc), value = TRUE)
se_columns <- grep("_se", names(wdbc), value = TRUE)
worst_columns <- grep("_worst", names(wdbc), value = TRUE)

boxplot(wdbc[, mean_columns], horizontal = T)
boxplot(wdbc[, se_columns], horizontal = T)
boxplot(wdbc[, worst_columns], horizontal = T)
```

```{r}
diagnosis_freq <- table(diagnosis)
diagnosis_freq

diagnosis_rel_freq <- prop.table(diagnosis_freq) * 100

pie(diagnosis_rel_freq, main = "% Distribution of Benign/Malignant Cancer", col = c("limegreen", "red2"))
```

### 1.2. Hierarchical Clustering: mtcars
```{r}
mtcars <- read.csv("data/mtcars.csv", header = T, sep = ",")
head(mtcars)
```

#### 1.2.1. Pre-processing and Normalizing: mtcars
```{r}
mtcars_categorical <- data.frame(
  cyl = mtcars$cyl,
  vs = mtcars$vs,
  am = mtcars$am,
  gear = mtcars$gear,
  carb = mtcars$carb
)

mtcars_numerical <- data.frame(
  mpg = mtcars$mpg,
  disp = mtcars$disp,
  hp = mtcars$hp,
  drat = mtcars$drat,
  wt = mtcars$wt,
  qsec = mtcars$qsec
)

mtcars_numerical_scaled <- data.frame(scale(mtcars_numerical))

mtcars_joined <- cbind(mtcars_numerical_scaled, mtcars_categorical)
rownames(mtcars_joined) <- mtcars$model
mtcars <- mtcars_joined
head(mtcars)
```

#### 1.2.2. Checking the internal structure: mtcars
```{r}
str(mtcars)
```

#### 1.2.3. Checking the row index
```{r}
rownames(mtcars)
```

#### 1.2.4. EDA: mtcars
```{r}
boxplot(scale(mtcars_numerical), horizontal = T)
```

```{r}
ggplot(mtcars_categorical, aes(x = factor(cyl), fill = factor(cyl))) +
  geom_bar() +
  theme_minimal()
ggplot(mtcars_categorical, aes(x = factor(vs), fill = factor(vs))) +
  geom_bar() +
  theme_minimal()
ggplot(mtcars_categorical, aes(x = factor(am), fill = factor(am))) +
  geom_bar() +
  theme_minimal()
ggplot(mtcars_categorical, aes(x = factor(gear), fill = factor(gear))) +
  geom_bar() +
  theme_minimal()
ggplot(mtcars_categorical, aes(x = factor(carb), fill = factor(carb))) +
  geom_bar() +
  theme_minimal()
```

```{r}
missing_mtcars <- sapply(mtcars, function(x) sum(is.na(x)))
missing_mtcars
```

## 2. Assessing Clustering Tendency
### 2.1. Statistical Method

#### 2.1.1. Hopkins Statistic: wdbc
```{r}
set.seed(69)

hopkins_wdbc <- hopkins(wdbc, m = ceiling(nrow(wdbc) / 10))
hopkins_wdbc
```

#### 2.1.2. Hopkins Statistic: mtcars
```{r}
set.seed(69)

hopkins_mtcars <- hopkins(mtcars, m = ceiling(nrow(mtcars) / 10))
hopkins_mtcars
```

### 2.2. Visual Method
#### 2.2.1. VAT: wdbc
```{r}
fviz_dist(
  dist(wdbc),
  show_labels = FALSE
) + labs(title = "wdbc")
```

#### 2.2.2. VAT: mtcars
```{r}
fviz_dist(
  dist(mtcars),
  show_labels = FALSE
) + labs(title = "mtcar")
```

#### 2.2.3. PCA: wdbc
```{r}
fviz_pca_ind(
  prcomp(wdbc),
  title = "PCA - wdbc",
  habillage = diagnosis,
  palette = "jco",
  geom = "point",
  ggtheme = theme_classic(),
  legend = "bottom"
)
```

#### 2.2.4. PCA: mtcars
```{r}
fviz_pca_ind(
  prcomp(mtcars),
  title = "PCA - mtcars",
  palette = "jco",
  geom = "point",
  ggtheme = theme_classic(),
  legend = "bottom"
)
```

## 3. Finding Optimal value of k

### 3.1. Dataset: wdbc
#### 3.1.1. Elbow Method: k-means
```{r}
wdbc_elbow_kmeans <- fviz_nbclust(wdbc, kmeans, method = "wss") + geom_vline(xintercept = 2, linetype = 2)
wdbc_elbow_kmeans
```

#### 3.1.2. Silhouette Width: k-means and pam
```{r}
wdbc_silhouette_kmeans <- fviz_nbclust(wdbc, kmeans, method = "silhouette")
wdbc_silhouette_pam <- fviz_nbclust(wdbc, pam, method = "silhouette")

wdbc_silhouette_kmeans +
  wdbc_silhouette_pam +
  plot_layout(ncol = 2)
```


#### 3.1.3. Gap Statistic: k-means and pam
```{r}
# wdbc_gap_kmeans <- fviz_nbclust(wdbc, kmeans, nstart = 50, method = "gap_stat", nboot = 500)
# wdbc_gap_pam <- fviz_nbclust(wdbc, pam, nstart = 50, method = "gap_stat", nboot = 800)
#
# wdbc_gap_kmeans +
#   wdbc_gap_pam +
#   plot_layout(ncol = 2)
```

#### 3.1.4. TODO: the positive negative bar plot

### 3.2. Dataset: mtcars
#### 3.2.1. Gap Statistic: k-means and pam
```{r, message = FALSE}
wdbc_gap_hierarchical <- fviz_nbclust(mtcars, hcut, nstart = 50, method = "gap_stat", nboot = 500)
wdbc_gap_hierarchical
```

#### 3.2.2. TODO: the positive negative bar plot

## 4. K-Means and PAM Clustering
### 4.1. K-means on wdbc
```{r}
set.seed(101)

color_palette <- c("red", "blue", "green", "pink", "purple", "lightblue")

km.res <- kmeans(wdbc, 2, nstart = 100)

kmeans_graph <- fviz_cluster(
  km.res,
  data = wdbc,
  palette = color_palette,
  ellipse.type = "convex",
  star.plot = TRUE,
  ellipse = TRUE,
  geom = "point",
  main = "K-Means Cluster Plot",
  ggtheme = theme_minimal()
)
kmeans_graph
```

### 4.2. PAM on wdbc
```{r}
set.seed(101)

pam.res <- pam(wdbc, 2)

pam_graph <- fviz_cluster(
  pam.res,
  data = wdbc,
  palette = color_palette,
  ellipse.type = "convex",
  star.plot = TRUE,
  ellipse = TRUE,
  geom = "point",
  main = "PAM Cluster Plot",
  ggtheme = theme_minimal()
)
pam_graph
```

### 4.3. Comparing the results of K-means and PAM
```{r}
kmeans_graph + pam_graph + plot_layout(ncol = 1)
```


### 4.4. Internal Validation of K-means and PAM
```{r}
intern_wdbc <- clValid(wdbc, 2:6, clMethods = c("kmeans", "hierarchical", "pam"), validation = "internal")

summary(intern_wdbc)
```

```{r}
op <- par(no.readonly = TRUE)
par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))

plot(intern_wdbc, legend = FALSE)

plot(nClusters(intern_wdbc), measures(intern_wdbc, "Dunn")[, , 1], type = "n", axes = FALSE, xlab = "", ylab = "")
legend("center", clusterMethods(intern_wdbc), col = 1:9, lty = 1:9, pch = paste(1:9))

par(op)
```

### 4.5. Stability Validation of K-means and PAM
```{r}
stab_wdbc <- clValid(wdbc, nClust = 2:6, clMethods = c("hierarchical", "kmeans", "pam"), validation = "stability")

optimal_scores_stab <- optimalScores(stab_wdbc)
optimal_scores_stab
```

```{r}
par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))

plot(stab_wdbc, measure = c("APN", "AD", "ADM", "FOM"), legend = FALSE)

plot(nClusters(stab_wdbc), measures(stab_wdbc, "APN")[, , 1], type = "n", axes = FALSE, xlab = "", ylab = "")
legend("left", clusterMethods(stab_wdbc), col = 1:9, lty = 1:9, pch = paste(1:9))
```

## 5. Hierarchical Clustering
### 5.1. Applying Various Linkage Methods
#### 5.1.1. Single Linkage Method
```{r}
res.dist <- dist(mtcars, method = "manhattan")

hc_single <- hclust(d = res.dist, method = "single")
grp_single <- cutree(hc_single, k = 2)

single_cluster <- fviz_cluster(
  list(data = mtcars, cluster = grp_single),
  palette = "jco",
  geom = "point",
  ellipse.type = "convex",
  show.clust.cent = FALSE,
  main = "Single Linkage Cluster",
  ggtheme = theme_minimal()
)

single_dendrogram <- fviz_dend(
  hc_single,
  cex = 0.5, # Increase the label size
  k = 2, # Number of clusters
  k_colors = "jco", # Color palette for clusters
  rect = TRUE,
  rect_border = "jco", # Add rectangle around clusters
  rect_fill = TRUE, # Fill the rectangle
  label_cols = "black", # Color of labels
  label_cex = 0.5, # Font size of labels
  main = "Single Linkage Dendrogram",
  ggtheme = theme_minimal()
)
single_dendrogram
```

#### 5.1.2. Complete Linkage Method
```{r}
hc_complete <- hclust(d = res.dist, method = "complete")
grp_complete <- cutree(hc_complete, k = 2)

complete_cluster <- fviz_cluster(
  list(data = mtcars, cluster = grp_complete),
  palette = "jco",
  geom = "point",
  ellipse.type = "convex",
  show.clust.cent = FALSE,
  main = "Complete Linkage Cluster",
  ggtheme = theme_minimal()
)

complete_dendrogram <- fviz_dend(
  hc_complete,
  cex = 0.5,
  k = 2,
  k_colors = "jco",
  rect = TRUE,
  rect_border = "jco",
  rect_fill = TRUE,
  label_cols = "black",
  label_cex = 0.5,
  main = "Complete Linkage Dendrogram",
  ggtheme = theme_minimal()
)
complete_dendrogram
```

#### 5.1.3. Average Linkage Method
```{r}
hc_average <- hclust(d = res.dist, method = "average")
grp_average <- cutree(hc_average, k = 2)

average_cluster <- fviz_cluster(
  list(data = mtcars, cluster = grp_average),
  palette = "jco",
  geom = "point",
  ellipse.type = "convex",
  show.clust.cent = FALSE,
  main = "Average Linkage Cluster",
  ggtheme = theme_minimal()
)

average_dendrogram <- fviz_dend(
  hc_average,
  cex = 0.5,
  k = 2,
  k_colors = "jco",
  rect = TRUE,
  rect_border = "jco",
  rect_fill = TRUE,
  label_cols = "black",
  label_cex = 0.5,
  main = "Average Linkage Dendrogram",
  ggtheme = theme_minimal()
)
average_dendrogram
```

#### 5.1.4. Ward D Linkage Method
```{r}
hc_ward_d <- hclust(d = res.dist, method = "ward.D")
grp_ward_d <- cutree(hc_ward_d, k = 2)

ward_d_cluster <- fviz_cluster(
  list(data = mtcars, cluster = grp_ward_d),
  palette = "jco",
  geom = "point",
  ellipse.type = "convex",
  show.clust.cent = FALSE,
  main = "Ward D Linkage Cluster",
  ggtheme = theme_minimal()
)

ward_d_dendrogram <- fviz_dend(
  hc_ward_d,
  cex = 0.5,
  k = 2,
  k_colors = "jco",
  rect = TRUE,
  rect_border = "jco",
  rect_fill = TRUE,
  label_cols = "black",
  label_cex = 0.5,
  main = "Ward D Linkage Dendrogram",
  ggtheme = theme_minimal()
)
ward_d_dendrogram
```

#### 5.1.5. Ward D2 Linkage Method
```{r}
hc_ward_d2 <- hclust(d = res.dist, method = "ward.D2")
grp_ward_d2 <- cutree(hc_ward_d2, k = 2)

ward_d2_cluster <- fviz_cluster(
  list(data = mtcars, cluster = grp_ward_d2),
  palette = "jco",
  geom = "point",
  ellipse.type = "convex",
  show.clust.cent = FALSE,
  main = "Ward D2 Linkage Cluster",
  ggtheme = theme_minimal()
)

ward_d2_dendrogram <- fviz_dend(
  hc_ward_d2,
  cex = 0.5,
  k = 2,
  k_colors = "jco",
  rect = TRUE,
  rect_border = "jco",
  rect_fill = TRUE,
  label_cols = "black",
  label_cex = 0.5,
  main = "Ward D2 Linkage Dendrogram",
  ggtheme = theme_minimal()
)
ward_d2_dendrogram
```

### 5.2. Comparing Linkage Methods
#### 5.2.1. Comparing the dendrograms
```{r}
single_dendrogram +
  complete_dendrogram +
  average_dendrogram +
  ward_d_dendrogram +
  ward_d2_dendrogram +
  plot_layout(ncol = 2)
```

#### 5.2.2. Comparing the clusters
```{r}
single_cluster +
  complete_cluster +
  average_cluster +
  ward_d_cluster +
  ward_d2_cluster +
  plot_layout(ncol = 2)
```

#### 5.2.3. Correlation between cophenetic distance and the original distance
```{r}
cor(res.dist, cophenetic(hc_single))
cor(res.dist, cophenetic(hc_complete))
cor(res.dist, cophenetic(hc_average))
cor(res.dist, cophenetic(hc_ward_d))
cor(res.dist, cophenetic(hc_ward_d2))
```

#### 5.2.4. Correlation Matrix
```{r}
dend_complete <- mtcars %>%
  dist %>%
  hclust("complete") %>%
  as.dendrogram
dend_single <- mtcars %>%
  dist %>%
  hclust("single") %>%
  as.dendrogram
dend_average <- mtcars %>%
  dist %>%
  hclust("average") %>%
  as.dendrogram
dend_centroid <- mtcars %>%
  dist %>%
  hclust("centroid") %>%
  as.dendrogram
dend_ward <- mtcars %>%
  dist %>%
  hclust("ward.D") %>%
  as.dendrogram
dend_ward2 <- mtcars %>%
  dist %>%
  hclust("ward.D2") %>%
  as.dendrogram

dend_list <- dendlist(
  "Complete" = dend_complete,
  "Single" = dend_single,
  "Average" = dend_average,
  "Centroid" = dend_centroid,
  "WardD" = dend_ward,
  "WardD2" = dend_ward2
)

cors <- cor.dendlist(dend_list)

round(cors, 2)
```

#### 5.2.5. Visualizing the Correlation Matrix
```{r}
corrplot(cors, "pie", "lower")
```

### 5.3. Alternative Hierarchical Clustering Methods
#### 5.3.1. Agglomerative Nesting
```{r}
res.agnes <- agnes(
  x = mtcars, # data matrix
  stand = TRUE, # Standardize the data
  metric = "manhattan", # metric for distance matrix
  method = "ward" # Linkage method
)

nesting_dendrogram <- fviz_dend(
  res.agnes,
  cex = 0.5,
  k = 2,
  k_colors = "jco",
  rect = TRUE,
  rect_border = "jco",
  rect_fill = TRUE,
  label_cols = "black",
  label_cex = 0.5,
  main = "Hierarchical Nested Clustering Dendrogram"
) + theme_minimal()
nesting_dendrogram
```

#### 5.3.2. Divisive Analysis Clustering
```{r}
res.diana <- diana(
  x = mtcars,
  stand = TRUE,
  metric = "manhattan"
)

divisive_dendrogram <- fviz_dend(
  res.diana,
  cex = 0.5,
  k = 2,
  k_colors = "jco",
  rect = TRUE,
  rect_border = "jco",
  rect_fill = TRUE,
  label_cols = "black",
  label_cex = 0.5,
  main = "Divisive Clustering Dendrogram"
) + theme_minimal()
divisive_dendrogram
```

#### 5.3.3.Comparing Alternative Hierarchical Clustering Methods
```{r}
nesting_dendrogram +
  divisive_dendrogram +
  plot_layout(ncol = 2)
```

## 5.4. Internal Validation of Hierarchical Clustering
```{r}
intern_mtcars <- clValid(mtcars, 2:6, clMethods = c("hierarchical", "kmeans", "pam"), validation = "internal")

summary(intern_mtcars)
```

```{r}
par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))

plot(intern_mtcars, legend = FALSE)

plot(nClusters(intern_mtcars), measures(intern_mtcars, "Dunn")[, , 1], type = "n", axes = FALSE, xlab = "", ylab = "")
legend("center", clusterMethods(intern_mtcars), col = 1:9, lty = 1:9, pch = paste(1:9))
```

## 5.4. Stability Validation of Hierarchical Clustering
```{r}
stab_mtcars <- clValid(mtcars, 2:6, clMethods = c("hierarchical", "kmeans", "pam"), validation = "stability")

optimal_scores_stab_mtcars <- optimalScores(stab_mtcars)
optimal_scores_stab_mtcars
```

```{r}
par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))

plot(stab_mtcars, measure = c("APN", "AD", "ADM", "FOM"), legend = F)

plot(nClusters(stab_mtcars), measures(stab_mtcars, "APN")[, , 1], type = "n", axes = F, xlab = "", ylab = "")
legend("center", clusterMethods(stab_mtcars), col = 1:9, lty = 1:9, pch = paste(1:9))

par(op)
```

